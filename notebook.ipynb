{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Property Prediction using Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook runs inferrence on a model trained on the PaiNN (Polarizable Atom Interaction Neural Network) architechture with the goal of predicting the QM9 property $U_0$ known as \"internal energy at 0K\". This notebook has been adapted from the template *minimal_example.py* in https://github.com/jonasvj/02456_painn_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "%pip install torch numpy lightning torch-geometric torchvision rdkit scipy tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 6\n",
    "# The path to the model we want to load\n",
    "path = f'trained_models/{layers}layers.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch  # Importing PyTorch for tensor operations and model training\n",
    "from tqdm import trange  # Importing tqdm for progress bar functionality\n",
    "import torch.nn.functional as F  # Importing functional interface for neural network operations\n",
    "from src.data import QM9DataModule  # Importing the data module for QM9 dataset handling\n",
    "from pytorch_lightning import seed_everything  # Importing function to set random seed for reproducibility\n",
    "from src.models import PaiNN, AtomwisePostProcessing  # Importing the model and post-processing class\n",
    "import sys\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "# Use GPU if available, otherwise fallback to CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/_96cjb497ngb81vl5_zn5rz80000gn/T/ipykernel_88045/2362900231.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pth = torch.load(path, map_location=torch.device(device))\n",
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading path: trained_models/6layers.pth\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading path: {path}\")\n",
    "\n",
    "# Load model from path\n",
    "pth = torch.load(path, map_location=torch.device(device))\n",
    "args = pth[\"args\"]\n",
    "seed_everything(args.seed)  # Set the random seed for reproducibility of results\n",
    "\n",
    "if args.use_high_matmul_precision:\n",
    "    print(\"Using high precision floats for matrix multiplications\")\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data module for QM9 dataset\n",
    "dm = QM9DataModule(\n",
    "    target=args.target,\n",
    "    data_dir=args.data_dir,\n",
    "    batch_size_train=args.batch_size_train,\n",
    "    batch_size_inference=args.batch_size_inference,\n",
    "    num_workers=args.num_workers,\n",
    "    splits=args.splits,\n",
    "    seed=args.seed,\n",
    "    subset_size=args.subset_size,\n",
    ")\n",
    "dm.prepare_data()  # Prepare the data (download, if necessary)\n",
    "dm.setup()  # Setup the training and validation/test splits\n",
    "# Get statistics for the target variable to normalize predictions\n",
    "y_mean, y_std, atom_refs = dm.get_target_stats(\n",
    "    remove_atom_refs=True, divide_by_atoms=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled PaiNN and AtomwisePostProcessing module\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): AtomwisePostProcessing(\n",
       "    (atom_refs): Embedding(100, 1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the PaiNN model with specified parameters\n",
    "painn = PaiNN(\n",
    "    num_message_passing_layers=args.num_message_passing_layers,\n",
    "    num_features=args.num_features,\n",
    "    num_outputs=args.num_outputs, \n",
    "    num_rbf_features=args.num_rbf_features,\n",
    "    num_unique_atoms=args.num_unique_atoms,\n",
    "    cutoff_dist=args.cutoff_dist,\n",
    ")\n",
    "\n",
    "# Instantiate post-processing to convert atomic contributions to predicted property\n",
    "post_processing = AtomwisePostProcessing(\n",
    "    args.num_outputs, y_mean, y_std, atom_refs\n",
    ")\n",
    "\n",
    "# Compile \n",
    "if args.compile:\n",
    "    painn = torch.compile(painn)\n",
    "    post_processing = torch.compile(post_processing)\n",
    "    print(\"Compiled PaiNN and AtomwisePostProcessing module\")\n",
    "\n",
    "# Load models from path\n",
    "painn.load_state_dict(pth[\"painn\"])\n",
    "post_processing.load_state_dict(pth[\"post_processing\"])\n",
    "\n",
    "painn.to(device)  # Move the model to the appropriate device (GPU/CPU)\n",
    "post_processing.to(device)  # Move the post-processing module to the same device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 5.605 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation phase to compute Mean Absolute Error (MAE) on test data\n",
    "mae = 0\n",
    "painn.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    # Iterate through batches of test data\n",
    "    for batch in dm.test_dataloader():\n",
    "        batch = batch.to(device)  # Move batch data to the appropriate device\n",
    "\n",
    "        # Forward pass to compute atomic contributions\n",
    "        atomic_contributions = painn(\n",
    "            atoms=batch.z,\n",
    "            atom_positions=batch.pos,\n",
    "            graph_indexes=batch.batch,\n",
    "        )\n",
    "        # Apply post-processing to obtain predictions from atomic contributions\n",
    "        preds = post_processing(\n",
    "            atoms=batch.z,\n",
    "            graph_indexes=batch.batch,\n",
    "            atomic_contributions=atomic_contributions,\n",
    "        )\n",
    "        # Accumulate Mean Absolute Error\n",
    "        mae += F.l1_loss(preds, batch.y, reduction='sum')\n",
    "\n",
    "# Average MAE across the entire test set\n",
    "mae /= len(dm.data_test)\n",
    "unit_conversion = dm.unit_conversion[args.target]  # Retrieve unit conversion function for the target\n",
    "print(f'Test MAE: {unit_conversion(mae):.3f} \\n')  # Print the final MAE after unit conversion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
